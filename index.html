<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Detección de Gestos con MediaPipe</title>
  <style>
    body {
      margin: 0;
      background: #fafafa;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    #video {
      position: relative;
      width: 640px;
      height: 480px;
      background: #000;
    }
    #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 640px;
      height: 480px;
      pointer-events: none;
    }
    #log {
      margin-top: 10px;
      width: 640px;
      font-size: 1.2em;
      color: #333;
    }
  </style>
</head>
<body>
  <h2>Detección de Gestos (MediaPipe)</h2>
  <div style="position: relative; width: 640px; height: 480px;">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="canvas"></canvas>
  </div>
  <div id="log">Esperando gesto...</div>

  <!-- Carga de MediaPipe -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const log = document.getElementById('log');

    async function init() {
      // Verifica si getUserMedia está disponible
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        log.textContent = 'getUserMedia no es compatible con este navegador.';
        return;
      }

      // Solicita acceso a la cámara
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
      } catch (err) {
        console.error('Error al acceder a la cámara:', err);
        log.textContent = 'No se pudo acceder a la cámara.';
        return;
      }

      // Espera a que el video esté listo
      video.addEventListener('loadedmetadata', async () => {
        video.play();

        // Carga y configura el reconocedor de gestos
        const vision = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
        );

        const gestureRecognizer = await GestureRecognizer.createFromModelPath(
          vision,
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/gesture_recognizer.task'
        );

        // Procesa cada cuadro de video
        async function processFrame() {
          const results = gestureRecognizer.recognizeForVideo(video, performance.now());

          ctx.clearRect(0, 0, canvas.width, canvas.height);

          if (results.handednesses.length > 0) {
            for (let i = 0; i < results.handednesses.length; i++) {
              const landmarks = results.landmarks[i];
              drawConnectors(ctx, landmarks, HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 2 });
              drawLandmarks(ctx, landmarks, { color: '#FF0000', lineWidth: 1 });

              const gesture = results.gestures[i][0];
              log.textContent = `Mano ${i + 1}: ${gesture.categoryName} (${(gesture.score * 100).toFixed(1)}%)`;
            }
          } else {
            log.textContent = 'Sin gesto claro';
          }

          requestAnimationFrame(processFrame);
        }

        processFrame();
      });
    }

    init();
  </script>
</body>
</html>
