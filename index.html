<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Detección de Gestos con MediaPipe</title>
  <style>
    body {
      margin: 0;
      background: #fafafa;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    #video, #canvas {
      position: absolute;
      top: 50px;
      width: 640px;
      height: 480px;
    }
    #canvas {
      z-index: 1;
      pointer-events: none;
    }
    #log {
      margin-top: 550px;
      width: 640px;
      font-size: 1.2em;
      color: #333;
    }
  </style>
</head>
<body>
  <h2>Detección de Gestos con MediaPipe</h2>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
  <div id="log">Esperando gesto...</div>

  <!-- Carga de MediaPipe -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest"></script>
  <script>
    const { FilesetResolver, GestureRecognizer, GestureRecognizerModelConfig, VisionRunningMode } = window;

    async function init() {
      const visionFiles = await FilesetResolver.forVisionTasks(
        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
      );

      const gestureRecognizer = await GestureRecognizer.createFromModelAndOptions(
        visionFiles,
        new GestureRecognizerModelConfig({
          modelAssetPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/gesture_recognizer.task',
          runningMode: VisionRunningMode.LIVE_STREAM,
          numHands: 2,
          minHandPresenceConfidence: 0.5,
          minTrackingConfidence: 0.5
        })
      );

      const video = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      const log = document.getElementById('log');

      // Solicitar acceso a la cámara
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
      } catch (err) {
        console.error('Error al acceder a la cámara:', err);
        log.textContent = 'No se pudo acceder a la cámara.';
        return;
      }

      video.addEventListener('loadedmetadata', () => {
        video.play();
        requestAnimationFrame(processFrame);
      });

      async function processFrame() {
        const results = await gestureRecognizer.recognizeForVideo(video, performance.now());
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        if (results.handedGestures.length) {
          results.multiHandLandmarks.forEach((landmarks, i) => {
            // Dibuja los puntos y conexiones de la mano
            window.drawConnectors(ctx, landmarks, window.HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 2 });
            window.drawLandmarks(ctx, landmarks, { color: '#FF0000', lineWidth: 1 });

            const best = results.handedGestures[i][0];
            log.textContent = `Mano ${i + 1}: ${best.categoryName} (${(best.score * 100).toFixed(1)}%)`;
          });
        } else {
          log.textContent = 'Sin gesto claro';
        }
        requestAnimationFrame(processFrame);
      }
    }

    init();
  </script>
</body>
</html>
